{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8b51d3-6196-47a8-8fea-fb963df96a02",
   "metadata": {},
   "source": [
    "## Data stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a38facb-d44b-4f46-9186-72b65b7f395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5db465-9b09-48d0-872e-4adad7e5ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required in the Data Stage\n",
    "import util_funcs\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c868c6df-c8f9-4b69-a7f8-1eb66f2561f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base directory: store\n",
      "\n",
      "data: store/data\n",
      "model: store/model\n",
      "vocab: store/vocab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Setup experiment directories\n",
    "BASE_DIR = 'store'\n",
    "data_dir, model_dir, vocab_dir = util_funcs.set_experiment_dirs(BASE_DIR)\n",
    "print(\n",
    "    f'base directory: {BASE_DIR}\\n\\n'\n",
    "    f'data: {data_dir}\\n'\n",
    "    f'model: {model_dir}\\n'\n",
    "    f'vocab: {vocab_dir}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d661c314-c394-4a22-b5e8-6e4cb1a8ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column width so to see the entire length of the `title` column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "## Read the data from store \n",
    "all_data = pd.read_csv(f'{data_dir}/all_news_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08197031-c6fe-4108-bdf4-de5a89919138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "BUSINESS         13.8%\n",
       "ENTERTAINMENT    13.8%\n",
       "HEALTH           13.8%\n",
       "NATION           13.8%\n",
       "SCIENCE           3.5%\n",
       "SPORTS           13.8%\n",
       "TECHNOLOGY       13.8%\n",
       "WORLD            13.8%\n",
       "Name: proportion, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the proportion of classes\n",
    "all_data.topic.value_counts(normalize=True).sort_index().mul(100).round(1).astype(str)+'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e843c406-c1b0-4561-885a-df5ad175d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split all data into train, test and dev (or validation) sets - 60%, 20%, 20% split such that class proportions are maintained\n",
    "## Stratified sampling\n",
    "train_df, test_df = train_test_split(all_data, test_size=0.2, stratify = all_data['topic'])\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.20, stratify = train_df['topic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d45a53-859e-440e-addd-8275e3ea26c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic\n",
      "BUSINESS         13.8%\n",
      "ENTERTAINMENT    13.8%\n",
      "HEALTH           13.8%\n",
      "NATION           13.8%\n",
      "SCIENCE           3.5%\n",
      "SPORTS           13.8%\n",
      "TECHNOLOGY       13.8%\n",
      "WORLD            13.8%\n",
      "Name: proportion, dtype: object\n",
      "topic\n",
      "BUSINESS         13.8%\n",
      "ENTERTAINMENT    13.8%\n",
      "HEALTH           13.8%\n",
      "NATION           13.8%\n",
      "SCIENCE           3.5%\n",
      "SPORTS           13.8%\n",
      "TECHNOLOGY       13.8%\n",
      "WORLD            13.8%\n",
      "Name: proportion, dtype: object\n",
      "topic\n",
      "BUSINESS         13.8%\n",
      "ENTERTAINMENT    13.8%\n",
      "HEALTH           13.8%\n",
      "NATION           13.8%\n",
      "SCIENCE           3.5%\n",
      "SPORTS           13.8%\n",
      "TECHNOLOGY       13.8%\n",
      "WORLD            13.8%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Check the proportion of classes in split datasets\n",
    "print(train_df.topic.value_counts(normalize=True).sort_index().mul(100).round(1).astype(str)+'%')\n",
    "print(test_df.topic.value_counts(normalize=True).sort_index().mul(100).round(1).astype(str)+'%')\n",
    "print(dev_df.topic.value_counts(normalize=True).sort_index().mul(100).round(1).astype(str)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85f7157-f825-486f-a390-365ea2e956f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the split datasets in store/data\n",
    "# Save the datasets\n",
    "util_funcs.save_data(train_df, data_dir, 'train_data.csv')\n",
    "util_funcs.save_data(dev_df, data_dir, 'dev_data.csv')\n",
    "util_funcs.save_data(test_df, data_dir, 'test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8124665-4131-40fd-bb18-3036c59adb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055b343-c984-4460-a162-62612cd4f851",
   "metadata": {},
   "source": [
    "## Modeling stage\n",
    "\n",
    "[TextVectorization()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) layer for title vectorization </br>\n",
    "[StringLookup()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) layer to convert the labels/topics to numerical indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302937b6-42bf-4f8b-91ba-321178247050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working folder for the project\n",
    "BASE_DIR = './store'\n",
    "\n",
    "# Max length and vocabulary size used \n",
    "MAX_LENGTH = 20\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# # Get the subdirectories that contain the experiment files\n",
    "# data_dir, model_dir, vocab_dir = lab_utils.set_experiment_dirs(BASE_DIR)\n",
    "\n",
    "# # Load the train and test sets\n",
    "# train_df = pd.read_csv(f'{data_dir}/train_data.csv')\n",
    "# dev_df = pd.read_csv(f'{data_dir}/dev_data.csv')\n",
    "# test_df = pd.read_csv(f'{data_dir}/test_data.csv')\n",
    "\n",
    "topic_lookup = tf.keras.layers.StringLookup(vocabulary=f'{vocab_dir}/labels.txt', num_oov_indices=0)\n",
    "\n",
    "## CREATE TEXT ENCODER`\n",
    "## Setup the String lookup and the Text Vectorization tensors for labels and topics respectively\n",
    "title_preprocessor = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE, output_sequence_length=MAX_LENGTH)\n",
    "##Calling adapt() on a TextVectorization layer is an alternative to passing in a precomputed vocabulary on construction via the vocabulary argument.\n",
    "# Extract the titles from the new training set\n",
    "train_inputs = train_df['title']\n",
    "title_preprocessor.adapt(train_inputs)\n",
    "\n",
    "# Save the new vocabulary\n",
    "util_funcs.save_vocab(title_preprocessor, vocab_dir)\n",
    "util_funcs.save_labels(topic_lookup, vocab_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d651fef-a4ac-4d0f-9dfa-bbcd433c7e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'in', 'to', 'be', 'will', 'the', 'of', 'why', '12',\n",
       "       'another', 'iphone', 'story', 'growth', 'apples', 'chapter',\n",
       "       'defining', 'for', 'and', 'on'], dtype='<U21')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(title_preprocessor.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03ee593-3a0f-4328-a3e6-7dae9b41b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string datasets to Tensorflow datasets\n",
    "train_ds = util_funcs.df_to_tfdata(train_df, topic_lookup, title_preprocessor, shuffle=True)\n",
    "dev_ds = util_funcs.df_to_tfdata(dev_df, topic_lookup, title_preprocessor)\n",
    "test_ds = util_funcs.df_to_tfdata(test_df, topic_lookup, title_preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa7524-b759-45e6-b6c5-ee4e01087968",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95ea257-d8b2-4fc9-af34-f7f25e1cfc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [[1517   71 2808   76 8525  608  889   85 7959   33    6  389  964    0\n",
      "     0    0    0    0    0    0]\n",
      " [ 938    1    1 7779    1   18 5755   32 2869    1    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [ 367    2    1  356 1598    7 1314    7    1 2355 1896   19    1    0\n",
      "     0    0    0    0    0    0]]\n",
      "\n",
      "labels:  [0 6 2]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_ds.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])\n",
    "# encoded_example = title_preprocessor(example)[:3].numpy()\n",
    "# encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae272f28-a26c-4dca-93cb-0609bd5e0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EMBEDDING_DIM = 24\n",
    "DENSE_DIM = 24\n",
    "topic_size = topic_lookup.vocabulary_size()\n",
    "\n",
    "## create the sequential deep learning model\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = 10000, output_dim=EMBEDDING_DIM, input_length=20, name=\"embedding_1\" ),\n",
    "    tf.keras.layers.Dense(units= DENSE_DIM, activation='relu', name=\"dense_2\"),\n",
    "    tf.keras.layers.Flatten(name = \"flatten_1\"),\n",
    "    tf.keras.layers.Dense(units= 8, activation = \"softmax\", name = \"dense_3\")\n",
    "])\n",
    "\n",
    "model1.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d88f3ed4-be3d-4cec-b6c6-5f9a8e9ce565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2176/2176 [==============================] - 11s 5ms/step - loss: 0.8471 - accuracy: 0.6954 - val_loss: 0.5522 - val_accuracy: 0.8072\n",
      "Epoch 2/5\n",
      "2176/2176 [==============================] - 10s 5ms/step - loss: 0.4354 - accuracy: 0.8491 - val_loss: 0.5283 - val_accuracy: 0.8188\n",
      "Epoch 3/5\n",
      "2176/2176 [==============================] - 10s 5ms/step - loss: 0.3491 - accuracy: 0.8797 - val_loss: 0.5458 - val_accuracy: 0.8214\n",
      "Epoch 4/5\n",
      "2176/2176 [==============================] - 10s 5ms/step - loss: 0.2910 - accuracy: 0.9003 - val_loss: 0.5807 - val_accuracy: 0.8180\n",
      "Epoch 5/5\n",
      "2176/2176 [==============================] - 10s 5ms/step - loss: 0.2415 - accuracy: 0.9191 - val_loss: 0.6361 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cf719954810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "# Train the model. Use the dev set to check if your model is overfitting.\n",
    "model1.fit(train_ds, epochs=NUM_EPOCHS, validation_data=dev_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5155fac-8047-48a6-b146-3f408ea59616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 1ms/step - loss: 0.6513 - accuracy: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6512677669525146, 0.809377133846283]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02154a73-f8f5-4404-81fd-b63e8037de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: store/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: store/model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model1.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50eddf-27c9-40f7-91ea-ead120e7952d",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "The first iteration of our model will likely underperform and we would need to make adjustments to improve it. Error analysis helps us determine the part of  process that needs to be updated to see improvement in the model. Likewise, it helps us to avoid focusing on parts that do not greatly affect the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9bc48-bf35-47c3-90af-64c862b87566",
   "metadata": {},
   "source": [
    "#### Prioritizing What to Work On\n",
    "\n",
    "Looking at the performance of your model on different categories of the data will help you decide how to improve its performance. In this case, you will evaluate the model on each of the 8 classes it's trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ec4ef21-3617-4a36-b999-f331c8d822ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY PER TOPIC:\n",
      "\n",
      "ENTERTAINMENT: 80.83 \n",
      "HEALTH: 83.33 \n",
      "TECHNOLOGY: 87.79 \n",
      "WORLD: 64.29 \n",
      "BUSINESS: 100.00 \n",
      "SPORTS: 91.58 \n",
      "NATION: 62.54 \n",
      "SCIENCE: 75.99 \n"
     ]
    }
   ],
   "source": [
    "# Get the list of topics\n",
    "topics = topic_lookup.get_vocabulary()\n",
    "\n",
    "# Evaluate the model's performance for each topic\n",
    "util_funcs.print_metric_per_topic(dev_df, topics, topic_lookup, title_preprocessor, model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cee9c1-a424-448e-bdec-8b338eda3205",
   "metadata": {},
   "source": [
    "From the results, you can check which ones stand out. If you have a baseline such as human-level performance (HLP), you can measure how far each category is from that value, then focus your efforts on the category that will bring the biggest overall improvement.\n",
    "\n",
    "On the other hand, this analysis can also help you spot errors. You might notice that performance on the `BUSINESS` topic seems suspiciously high compared to the rest. See if you can find why that is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e729a0c4-5aca-4b63-9575-41d8ccac7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([\"Why iPhone 12 Will Be Another 'Defining Chapter' In Apple's Growth Story\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b = train_df[train_df.topic ==\"BUSINESS\"]\n",
    "print(train_b.shape)\n",
    "train_b['title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d195463-5547-4fef-8892-928188039dc0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "You might have noticed that the titles for all articles are the same: `\"Why iPhone 12 Will Be Another 'Defining Chapter' In Apple's Growth Story\"`. The model only learned this pattern, so it will likely not generalize well when real-world business-related titles come in. \n",
    "\n",
    "After some investigation, you find out that the previous developer accidentally overwrote the columns while fixing a character encoding. Luckily, there is a backup file (correct_all_news.csv in store) which contains the original values. You can now procede with a new experiment using the correct values. To do so, generate train, dev, and test sets again and save these datasets to a folder named `store2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae62fae-1df5-432e-a6ca-7f04aaab8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment folder\n",
    "BASE_DIR = './store2'\n",
    "\n",
    "# Set the subdirectories that will contain the experiment files\n",
    "data_dir, model_dir, vocab_dir = util_funcs.set_experiment_dirs(BASE_DIR)\n",
    "\n",
    "# Load the backup CSV\n",
    "#combined_df = pd.read_csv(f'./.backup.csv')\n",
    "combined_df = pd.read_csv(f'./store/correct_all_news.csv')\n",
    "\n",
    "# Generate train, dev, and test sets as you did before.\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, stratify=combined_df['topic'])\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.25, stratify=train_df['topic'])\n",
    "\n",
    "# Save the datasets under the E3 folder\n",
    "util_funcs.save_data(train_df, data_dir, 'train_data.csv')\n",
    "util_funcs.save_data(dev_df, data_dir, 'dev_data.csv')\n",
    "util_funcs.save_data(test_df, data_dir, 'test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1831dcbd-0697-4055-9914-89155717a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new vocabulary based on the new training set\n",
    "train_inputs = train_df['title']\n",
    "title_preprocessor.adapt(train_inputs)\n",
    "\n",
    "# Save the new vocabulary and labels\n",
    "\n",
    "util_funcs.save_vocab(title_preprocessor, vocab_dir)\n",
    "util_funcs.save_labels(topic_lookup, vocab_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b35232b0-d3e9-49ba-a76d-caef84dfecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'to', 'in', 'the', 'of', 'for', 'and', 'on', 'a',\n",
       "       'covid19', 'with', 'new', 'as', 'coronavirus', 'is', 'after', 'at',\n",
       "       'from', 'by'], dtype='<U25')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = np.array(title_preprocessor.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d262b6b3-3cc1-4d00-9e0a-988e34be1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2040/2040 [==============================] - 10s 5ms/step - loss: 1.3467 - accuracy: 0.5096 - val_loss: 0.8528 - val_accuracy: 0.7105\n",
      "Epoch 2/5\n",
      "2040/2040 [==============================] - 10s 5ms/step - loss: 0.6519 - accuracy: 0.7789 - val_loss: 0.7168 - val_accuracy: 0.7631\n",
      "Epoch 3/5\n",
      "2040/2040 [==============================] - 10s 5ms/step - loss: 0.5024 - accuracy: 0.8313 - val_loss: 0.7354 - val_accuracy: 0.7624\n",
      "Epoch 4/5\n",
      "2040/2040 [==============================] - 10s 5ms/step - loss: 0.4252 - accuracy: 0.8571 - val_loss: 0.7724 - val_accuracy: 0.7607\n",
      "Epoch 5/5\n",
      "2040/2040 [==============================] - 10s 5ms/step - loss: 0.3641 - accuracy: 0.8787 - val_loss: 0.8316 - val_accuracy: 0.7562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cf6e06d6390>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now, we convert the dataframes to tf data & train model again\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Convert the dataframes to numeric features. Remember to shuffle the training set.\n",
    "train_ds = util_funcs.df_to_tfdata(train_df, topic_lookup, title_preprocessor,shuffle=True)\n",
    "dev_ds = util_funcs.df_to_tfdata(dev_df, topic_lookup, title_preprocessor)\n",
    "test_ds = util_funcs.df_to_tfdata(test_df, topic_lookup, title_preprocessor)\n",
    "\n",
    "# Reset the model weights\n",
    "model2 = util_funcs.model_reset_weights(model1)\n",
    "\n",
    "# Train the model\n",
    "model2.fit(train_ds, epochs = NUM_EPOCHS, validation_data = dev_ds, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58181e3a-28cd-4618-b422-08a0df26bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 1ms/step - loss: 0.8385 - accuracy: 0.7585\n",
      "INFO:tensorflow:Assets written to: ./store2/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./store2/model/assets\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set and write the results on the experiment tracker\n",
    "model2.evaluate(test_ds)\n",
    "\n",
    "# Save the model to model_dir\n",
    "model2.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7b2f881-5d57-4258-96cd-6222bf89c728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY PER TOPIC:\n",
      "\n",
      "ENTERTAINMENT: 83.13 \n",
      "HEALTH: 80.27 \n",
      "TECHNOLOGY: 85.73 \n",
      "WORLD: 62.33 \n",
      "BUSINESS: 72.67 \n",
      "SPORTS: 87.07 \n",
      "NATION: 58.33 \n",
      "SCIENCE: 74.97 \n"
     ]
    }
   ],
   "source": [
    "##Now evaluate the model again on each topic. You should see the accuracy on the business articles drop from 100% \n",
    "##because the model has to learn more words related to the topic.\n",
    "util_funcs.print_metric_per_topic(dev_df, topics, topic_lookup, title_preprocessor, model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a8ed68f-03e8-44d7-ad3f-f6ecc9770749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: Tropical Storm Isaias remnants to wash over Quebec, heavy rain\n",
      "\n",
      "label: SCIENCE\n",
      "prediction: NATION\n",
      "title: Explained: A method proposed for converting PPE into biofuels\n",
      "\n",
      "label: BUSINESS\n",
      "prediction: NATION\n",
      "title: Nigeria eyes record 12.65 trillion naira spending plan for 2021 - document\n",
      "\n",
      "label: ENTERTAINMENT\n",
      "prediction: NATION\n",
      "title: Store owner slams ‘teen influencer’ over ‘entitled’ social media request: ‘Please stop asking’\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: Kashamu: Backstory of Obasanjo’s letter to the dead\n",
      "\n",
      "label: ENTERTAINMENT\n",
      "prediction: NATION\n",
      "title: Spotlight on business families amid Supreme Court’s ruling on HUFs\n",
      "\n",
      "label: BUSINESS\n",
      "prediction: NATION\n",
      "title: Groundworks boss banned for false tax returns\n",
      "\n",
      "label: BUSINESS\n",
      "prediction: NATION\n",
      "title: ‘It’s a warning light’: Mayor de Blasio talks about COVID outbreak in Brooklyn\n",
      "\n",
      "label: HEALTH\n",
      "prediction: NATION\n",
      "title: ESB: Fault In Calverstown.\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: KUL now has connection to 30 cities in 20 countries\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: $340m in London law firm's account suspected of 1MDB connection\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: Zhang Yuhuan: Chinese court clears man of murder after 27 years in prison\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: Robin Hood Army closes in on vow to feed 30 million Covid-hit before Independence Day\n",
      "\n",
      "label: TECHNOLOGY\n",
      "prediction: NATION\n",
      "title: ‘Disgusted’ Argos shopper ‘sent text from delivery driver asking her if she is single’ after he dropped off a\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: Tanzania: A Tribute to Former President Benjamin Mkapa of Tanzania\n",
      "\n",
      "label: HEALTH\n",
      "prediction: NATION\n",
      "title: Fears for Victoria’s healthcare workers amid reported PPE shortage\n",
      "\n",
      "label: BUSINESS\n",
      "prediction: NATION\n",
      "title: DynaEnergetics Introduces Igneo™ Intrinsically Safe™ Initiating System for High-Temperature Mining Applications\n",
      "\n",
      "label: HEALTH\n",
      "prediction: NATION\n",
      "title: UK govt trying to reassure public over planned school reopenings\n",
      "\n",
      "label: WORLD\n",
      "prediction: NATION\n",
      "title: At least five dead and several injured as flight crash lands at airport in Kerala\n",
      "\n",
      "label: SPORTS\n",
      "prediction: NATION\n",
      "title: Rate or hate: How every NRL team has recruited for 2020 and beyond\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get examples in the dev set that predicted `NATION` but the ground truth label is different\n",
    "util_funcs.get_errors(model2, dev_df, title_preprocessor, topic_lookup, 'NATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac995f8-b661-4e96-b3a5-a89ad755554e",
   "metadata": {},
   "source": [
    "Although some predictions are indeed mistakes, you might notice that some examples might also be related to two categories. For example, this title: `COVID-19 hospital admissions up slightly across St. Louis area` sounds like it can both be a `HEALTH` and `NATION` article. \n",
    "\n",
    "You need to ask if the human labellers who provided the ground truth have clear instructions on how to label such topics. If some of them label COVID articles as `HEALTH` while others pick `NATION`, then this ambiguity will likely affect the model negatively.\n",
    "\n",
    "If a clear rule for choosing a single topic cannot be clearly defined, one way you can improve human-level performance is to allow labelers to select more than one topic. So, instead of just having this table when labelling:\n",
    "\n",
    "| Title      | Topic |\n",
    "| -----------| ----- |\n",
    "| Title 1    |       |\n",
    "| Title 2    |       |\n",
    "| Title 3    |       |\n",
    "\n",
    "They can have something like this instead where they can mark several categories for a title:\n",
    "\n",
    "| Title      | ENTERTAINMENT | HEALTH | TECHNOLOGY | WORLD | BUSINESS | SPORTS | NATION | SCIENCE |\n",
    "| -----------| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |\n",
    "| Title 1    |       |       |       |       |       |       |       |       |\n",
    "| Title 2    |       |       |       |       |       |       |       |       |\n",
    "| Title 3    |       |       |       |       |       |       |       |       |\n",
    "\n",
    "One other approach is to merge certain topics that are related to each other. So instead of having 8 classes, you can decide to only have 6: `ENTERTAINMENT`, `HEALTH`, `BUSINESS`, `SPORTS`, `WORLD and NATION` and `SCIENCE and TECHNOLOGY`. \n",
    "\n",
    "When making decisions like these, you need to get buy-in from the product/business owner because this will also impact other aspects of their operations. For example, this might mean that the article will appear in several parts of the News App, or their current system might break because some categories no longer exist.\n",
    "\n",
    "As a proof-of-concept, let's check if the second to the top class prediction of the model corresponds to the ground truth labels. The model is originally compiled to only get the top prediction of the softmax output. You can recompile the model to reward it if it the ground truth is in the top two predictions. You can use the [SparseTopKCategoricalAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseTopKCategoricalAccuracy) metric for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c262db0-ac7d-4348-845c-0369493dc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 1ms/step - loss: 0.8316 - sparse_top_k_categorical_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8316344022750854, 0.8820960521697998]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the top-K accuracy to 2\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2)]             \n",
    "             )\n",
    "\n",
    "# Check the accuracy\n",
    "model2.evaluate(dev_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b018d1af-9852-45f1-b41c-eb0fd98945c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY PER TOPIC:\n",
      "\n",
      "ENTERTAINMENT: 90.73 \n",
      "HEALTH: 90.53 \n",
      "TECHNOLOGY: 92.47 \n",
      "WORLD: 83.93 \n",
      "BUSINESS: 85.23 \n",
      "SPORTS: 91.67 \n",
      "NATION: 83.53 \n",
      "SCIENCE: 85.70 \n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy per topic\n",
    "util_funcs.print_metric_per_topic(dev_df, topics, topic_lookup, title_preprocessor, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d57e6-364c-474e-9dbf-256871eaac2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
